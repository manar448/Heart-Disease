{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898d5313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LogisticRegression params: {'C': 1, 'solver': 'liblinear'}\n",
      "Best LogisticRegression accuracy: 0.815191256830601\n",
      "----------\n",
      "Best RandomForest params: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best RandomForest accuracy: 0.8053551912568306\n",
      "----------\n",
      "Best SVM params: {'C': 0.1, 'kernel': 'linear'}\n",
      "Best SVM accuracy: 0.821639344262295\n",
      "----------\n",
      "\n",
      "Baseline vs Optimized Performance:\n",
      "             Unnamed: 0  Accuracy  F1 Score   ROC AUC\n",
      "0  Logistic Regression  0.868852  0.870968  0.946659\n",
      "1        Decision Tree  0.704918  0.735294  0.700970\n",
      "2        Random Forest  0.786885  0.786885  0.887931\n",
      "3                  SVM  0.868852  0.870968  0.931573\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load data\n",
    "X = pd.read_csv(\"D:\\AI & ML Sprints\\data\\selected_features.csv\")\n",
    "y = pd.read_csv(\"D:\\AI & ML Sprints\\data\\cleaned_heart_disease.csv\")['target']\n",
    "\n",
    "# Define models and parameter grids\n",
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'solver': ['liblinear', 'saga']\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [None, 10],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(probability=True),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform tuning and save best models\n",
    "best_models = {}\n",
    "for name, config in models.items():\n",
    "    # Grid Search\n",
    "    gs = GridSearchCV(\n",
    "        estimator=config['model'],\n",
    "        param_grid=config['params'],\n",
    "        cv=5,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    gs.fit(X, y)\n",
    "    \n",
    "    # Save best model\n",
    "    best_models[name] = gs.best_estimator_\n",
    "    joblib.dump(gs.best_estimator_, f'D:/AI & ML Sprints/models/best_{name}.pkl')\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Best {name} params:\", gs.best_params_)\n",
    "    print(f\"Best {name} accuracy:\", gs.best_score_)\n",
    "    print(\"----------\")\n",
    "\n",
    "# Compare with baseline performance\n",
    "baseline_metrics = pd.read_csv('D:/AI & ML Sprints/results/supervised_metrics.csv')\n",
    "print(\"\\nBaseline vs Optimized Performance:\\n\", baseline_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc5a36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/AI & ML Sprints/models/final_pipeline.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Load preprocessing steps from earlier\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age', 'trestbps', 'chol']),\n",
    "        ('cat', OneHotEncoder(), ['cp', 'thal'])\n",
    "    ])\n",
    "\n",
    "# Create final pipeline with best model (e.g., LogisticRegression)\n",
    "best_model = best_models['LogisticRegression']\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', best_model)\n",
    "])\n",
    "\n",
    "# Save complete pipeline\n",
    "joblib.dump(final_pipeline, 'D:/AI & ML Sprints/models/final_pipeline.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
